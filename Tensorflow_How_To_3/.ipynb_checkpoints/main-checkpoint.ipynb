{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n",
    "# Understanding And Implementing <font color=darkcyan>CNNs</font> For <font color=darkpink>NLP</font> With <font color=orange>Tensorflow</font>\n",
    "***\n",
    "***\n",
    "# Let's Start by Understanding HOW <font color=darkcyan>CNNs</font> Can Be Used For <font color=darkpink>NLP</font></center>\n",
    "***\n",
    "\n",
    "### <font color=darkcyan>CNN -- Convolutional Neural Network</font><br><br> <font color=darkpink>NLP -- Natural Language Processing</font>\n",
    "\n",
    "***\n",
    "\n",
    "When we hear about Convolutional Neural Network (CNNs), we typically think of Computer Vision\n",
    "- CNNs were responsible for major breakthroughs in Image Classification\n",
    "- CNNs are the core of most Computer Vision systems today\n",
    "    - Facebook’s automated photo tagging\n",
    "    - Self-driving cars\n",
    "    - Advanced counting algorithms\n",
    "    - SLAM and other autonomous movement based off localization\n",
    "    - Many more...\n",
    "\n",
    "More recently we’ve also started to apply CNNs to problems in Natural Language Processing and we've gotten some interesting results\n",
    "\n",
    "***\n",
    "**In this how-to:**\n",
    "1. I’ll try to summarize what CNNs are\n",
    "2. How are CNNs used in NLP\n",
    "3. The intuitions behind CNNs\n",
    "    - Somewhat easier to understand for the Computer Vision use case, so I’ll start there, and then slowly move towards NLP\n",
    "4. Implement a CNN towards Text Classification Utilizing Only Tensorflow (No Keras)\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Back to Basics (1) : What is a <font color=darkcyan>Convolution</font> ??\n",
    "***\n",
    "\n",
    "Convolution is a mathematical operation defined as a function derived from two given functions by integration that expresses how the shape of one is modified by the other. Now that's confusing as hell, but the idea is that a convolution links two functions together. If we consider one function to be the original image, and the second function to be some smaller image (a kernel), than a convolution operation simply explains a relationship between these two iamges.\n",
    "***\n",
    "**Let's look a bit more simplistically at the convolution operation and how it is used for computer vision:**\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "The **“convolution” operation** for computer vision is, at it's core, a tool used to extract features from an input image \n",
    "- A **convolution** preserves the spatial relationship between pixels by learning image features using small squares of input data\n",
    "    - We will not go into the mathematical details of the **convolution operation** here, but will try to understand how it works intuitively\n",
    "    - NOTE: The word Image here means any matrix with at least 3 dimensions -- **[Width**, **Height**, **Channels]**\n",
    "\n",
    "***\n",
    "Every image can be considered as a matrix of pixel values having at least 3 dimensions **[Width, Height, Channels]**\n",
    "- Consider a 5 x 5 image whose pixel values are only 0 and 1\n",
    "    - NOTE: For a grayscale image, pixel values range from 0 to 255\n",
    "    - NOTE: The green matrix below is a grayscale image whose values have been squished to be either 0 or 1 -- *i.e. binarization via thresholding*)\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "![cnn_image_for_gif](inline_images/cnn_image_for_gif.png)\n",
    "\n",
    "                     Fig. 1. This is the 5 x 5 image with pixel values being either 0 (black) or 1 (white)\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "![cnn_kernel_for_gif](inline_images/cnn_kernel_for_gif.png)\n",
    "\n",
    "                Fig. 2. This is the 3 x 3 image (kernel) with 'pixel' values being either 0 (black) or 1 (white)\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "![cnn_gif](inline_images/cnn_gif.gif)\n",
    "\n",
    "             Fig. 3. This is a gif showing the convolution operation (kernel over image) producing an output feature\n",
    "                             The output feature is often called a 'convolved feature' or a 'feature map'\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Take a moment to understand how the computation above is being done**\n",
    "***\n",
    "1. We slide the orange matrix over our original image (green) 1 pixel at a time (stride=1)\n",
    "2. For every position, we compute element wise multiplication (between the two matrices)\n",
    "3. We add the multiplication outputs to get the final integer which forms a single element of the output matrix (pink)\n",
    "    \n",
    "                --> NOTE: The 3×3 matrix only “sees” a PART (window) of the input image in each stride\n",
    "***\n",
    "**Let's See An Example Calculation To Illustrate How The Convolution is Done (Dot Product)**\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Example: Convolution For Bottom Right Hand Feature Value *( 3rd Row to 5th Row, 3rd Col to 5th Col, Indicated With Asterisk )***\n",
    "***\n",
    "       IMAGE             KERNEL                             MULTIPLICATION               ADDITION           1 CELL OF OUTPUT    \n",
    "                                                     _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
    "    |1|1|1|0|0|                                     |                                                 |\n",
    "    |0|1|1|1|0|          [1|0|1]                    |  [1*1|1*0|1*1]   [1|0|1]       [1]+[0]+[1] +    |\n",
    "    |0|0[1|1|1]*  <--->  [0|1|0]  --CONVOLUTION-->  |  [1*0|1*1|0*0] = [0|1|0] ----> [0]+[1]+[0] +    |      =     [4]\n",
    "    |0|0[1|1|0]*         [1|0|1]                    |  [1*1|0*0|0*1]   [1|0|0]       [1]+[0]+[0] ...  |\n",
    "    |0|1[1|0|0]*                                    |_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _|\n",
    "         * * *\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Convolution Terminology**\n",
    "***\n",
    "- The 3×3 matrix above is called:\n",
    "    - ***kernel*** or...\n",
    "    - ***filter*** or...\n",
    "    - ***feature detector***\n",
    "<br>\n",
    "<br>\n",
    "- The matrix formed by sliding the kernel over the image and computing the *dot product* is called:\n",
    "    - ***Convolved Feature*** or...\n",
    "    - ***Activation Map*** or\n",
    "    - ***Feature Map***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "It is evident from the animation above that different values of the *kernel* matrix will produce different *Feature Maps* for the same input image\n",
    "***\n",
    "**As an example, consider the following input image:**\n",
    "***\n",
    "![conv_kernel_original](inline_images/conv_kernel_original.png)\n",
    "\n",
    "                     Fig. 4. This is the original image that the different kernels will be applied to\n",
    "***\n",
    "**Here are various kernels, as shown on Wikipedia [__[link](https://en.wikipedia.org/wiki/Kernel_(image_processing)__], and the various effects they have on the image**\n",
    "***\n",
    "![conv_kernel_wiki](inline_images/conv_kernel_wiki.PNG)\n",
    "\n",
    "         Fig. 5. These are several kernels and their respective outputs w.r.t. to the original image (source: Wikipedia)\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**Let's Look At a Gif Showing Two Convolution Operations On The Same Image Using Different Filters**\n",
    "***\n",
    "![kernel_conv_example_gif](inline_images/kernel_conv_example.gif)\n",
    "\n",
    "     Fig. 6. This is a gif showing two convolution operations on the same image using different kernels (source: cs.nyu.edu)\n",
    "\n",
    "***\n",
    "Description of Above GIF\n",
    "- A filter (with red outline) slides over the input image (convolution operation) to produce a feature map. \n",
    "- The convolution of another filter (with the green outline), over the same image gives a different feature map as shown\n",
    "- It is important to note that the Convolution operation captures the local dependencies in the original image\n",
    "- Also notice how these two different filters generate different feature maps from the same original image\n",
    "- Remember that the image and the two filters above are just numeric matrices as we have discussed above\n",
    "***\n",
    "Filter/Kernel Values and Size\n",
    "- In practice, a CNN learns the values of these filters on its own during the training process\n",
    "    - Although we still need to specify parameters such as number of filters, filter size, architecture of the network etc. before the training process\n",
    "- The more number of filters we have, the more image features get extracted and the better our network becomes at recognizing patterns in images  \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**The size of the Feature Map (Convolved Feature) is controlled by *three parameters* that we need to decide before the convolution step is performed:**\n",
    "<br>\n",
    "***\n",
    "**1. Depth:** \n",
    "<br>\n",
    "***\n",
    "- **Depth** corresponds to the number of filters we use for the convolution operation\n",
    "- In the network shown in Figure 7, we are performing convolution of the original boat image using three distinct filters\n",
    "    - This produces three different feature maps as shown\n",
    "    - You can think of these three feature maps as stacked 2d matrices, so, the **depth** of the feature map would be three.\n",
    "***        \n",
    "![depth_image](inline_images/depth.png)\n",
    "\n",
    "             Fig. 7. This is an image showing a convolution operation performed with 3 distinct filters\n",
    "\n",
    "***\n",
    "**2. Stride:** \n",
    "<br>\n",
    "***\n",
    "- **Stride** is the number of pixels by which we shift our filter matrix over the input matrix each step\n",
    "    - When the **stride** is 1 then we move the filters one pixel at a time\n",
    "    - When the **stride** is 2, then the filters jump two pixels at a time as we slide them around\n",
    "        - Having a larger **stride** will produce smaller feature maps (unless we *pad*)\n",
    "<br>\n",
    "<br>\n",
    "***\n",
    "**3. Zero-Padding:** \n",
    "<br>\n",
    "***\n",
    "- Sometimes, it is convenient to **pad** the input matrix with zeros around the border (sometimes simply called ***padding***)\n",
    "    - **Zero-padding** is done so that we can apply the filter to bordering elements of our input image matrix\n",
    "    - A nice feature of **zero-padding** is that it allows us to control the size of the feature maps\n",
    "        - Adding **zero-padding** is also called *wide convolution*, and not using **zero-padding** would be a *narrow convolution*\n",
    "        - We will discuss wide and narrow convolutions in detail later\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Back to Basics (2) : What's a <font color=darkcyan>Convolutional Neural Network</font> ??\n",
    "***\n",
    "\n",
    "Now you know what convolutions are... But what about CNNs? \n",
    "- CNNs are basically just several layers of convolutions with ***nonlinear activation functions*** like ***ReLU*** or ***tanh*** applied to the results\n",
    "    - This pretty much means that we check a part of the image using the kernel and if it ***sees*** something similar to itself than it will ***activate***\n",
    "    - i.e. If a kernel to detect circles was on a part of an image with a circle, it will have a significant output from a nonlinear activation function\n",
    "\n",
    "- In a traditional feedforward neural network we connect each input neuron to each output neuron in the next layer\n",
    "    - Known as a ***fully connected layer (FC layer)***, or ***affine layer***\n",
    "    - <font color=red>**In CNNs we don’t do that**</font>\n",
    "\n",
    "\n",
    "                     \n",
    "                    Instead, we use convolutions over the input layer to compute the output\n",
    "                     \n",
    "\n",
    "\n",
    "- This results in local connections, where each region of the input is connected to a neuron in the output\n",
    "- Each layer applies different filters, typically hundreds or thousands like the ones showed above, and combines their results\n",
    "- There’s also something something called pooling (subsampling) layers, but I’ll get into that later\n",
    "- During the training phase, a CNN automatically learns the values of its filters based on the task you want to perform (as mentioned earlier)\n",
    "    - For example in Image Classification: \n",
    "        - A CNN may learn to detect edges from raw pixels in the first layer\n",
    "        - The CNN may then use the edges to detect simple shapes in the second layer\n",
    "        - It would then then use these shapes to deter higher-level features\n",
    "        - This process continues with increasing levels of abstraction (faces, groupings, assemblies, etc.)\n",
    "        - **The last layer is then a classifier that uses these high-level features**\n",
    "\n",
    "***\n",
    "**Let's look at an example of a full Convolutional Neurel Network For Image Classification:**\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "![CNN](inline_images/CNN.png)\n",
    "\n",
    "        Fig. 8. This is an image showing a convolution neurel network for image classification (Softmax for 4 Outputs)\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**CNN Computation Terminology**\n",
    "\n",
    "***\n",
    "Here are two common ideas that will help us understand CNNs and are worth paying attention to: **Location Invariance** and **Local Compositionality**\n",
    "***\n",
    "**Location Invariance**\n",
    "- Let’s say you want to classify whether or not there’s an elephant in an image\n",
    "    - **Local invariance** is the practice of desiring to be able to find an elephant regardless of where it occurs in the image\n",
    "        - Only being able to detect elephants in the bottom left hand corner is not particularly useful... hence the importance of **location invariance**\n",
    "        - In practice *pooling* will also give invariance to translation/rotation/scaling... but more on that later...\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "**Local Compositionality (IN MY OPINION THIS IS THE KEY TO THE WHOLE THING)**\n",
    "- Each filter composes a local patch of lower-level features into higher-level representation\n",
    "    - This is the main strength of CNNs\n",
    "    - This key aspect of CNNs is highly intuitive as it makes sense that you built edges from pixels, shapes from edges, objects from edges... and so on\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Back to Basics (3) : What is <font color=darkpink>Natural Language Processing</font> ??\n",
    "***\n",
    "\n",
    "Now you know what convolutions and convolution neurel networks are... but what about NLP? \n",
    "- Natural Language Processing, or NLP, is the sub-field of AI that is focused on enabling computers to understand and process human languages\n",
    "                \n",
    "              SIDENOTE: The study of human language is an example of UNSTRUCTURED Machine Learning\n",
    "\n",
    "***\n",
    "**Let's look at an example animation showing some unstructured data extraction that utilizes an NLP backend**\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "![London_NLP](inline_images/london_nlp.gif)\n",
    "\n",
    "             Fig. 9. Unstructured Data Extraction For Facts About London (Source: NLP_IS_FUN.. link below)\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**For more information on the basics of NLP I will link here to a tremendously well done article explaining the basics all the way through pipeline development... consider it a prerequisite for continuing the tutorial**\n",
    "***\n",
    "\n",
    "**As of November 26th, 2018, I have created/started-to-create a document to help better understand tradtional NLP... it is very similar to NLP_IS_FUN, but I tried to tailor it to my interests and locations and expand on it**\n",
    "\n",
    "\n",
    "***\n",
    "__[LINK_TO_NLP_IS_FUN](https://medium.com/@ageitgey/natural-language-processing-is-fun-9a0bff37854e)__\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## How Do We Apply <font color=darkcyan>Convolutional Neural Networks</font> to <font color=darkpink>Natural Language Processing</font> ??\n",
    "***\n",
    "\n",
    "Instead of image pixels, the input to most NLP tasks are sentences or documents represented as a matrix\n",
    "- Each row of the matrix corresponds to one token, typically a word, but it could be a character\n",
    "    - That is, each row is vector that represents a word\n",
    "        - Typically, these vectors are word embeddings (low-dimensional representations) like word2vec or GloVe\n",
    "        - They could also be one-hot vectors that index the word into a vocabulary\n",
    "        - These *representations* are usually made by someone else and we simply steal them as they are opensourced\n",
    "    - For a 10 word sentence using a 100-dimensional embedding we would have a 10×100 matrix as our input... Our ***'image'***\n",
    "\n",
    "In vision, our filters slide over local patches of an image, but in NLP we typically use filters that slide over full rows of the matrix (words)\n",
    "- The “width” of our filters is usually the same as the width of the input matrix\n",
    "- The height, or region size, may vary, but sliding windows over 2-5 words at a time is typical\n",
    "\n",
    "***\n",
    "**Putting all the above together, a <font color=darkcyan>Convolutional Neural Networks</font> for <font color=darkpink>Natural Language Processing</font> may look like this:**\n",
    "<br>\n",
    "<br>\n",
    "*Take a few minutes and try understand this picture and how the dimensions are computed*\n",
    "<br>\n",
    "*Ignore the pooling for now, we’ll explain that later*\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "![CNN_FOR_NLP](inline_images/CNN_for_NLP_1.png)\n",
    "\n",
    "            Fig. 10. Image Showing The Structure of a CNN That Is Used for NLP and the Flow of Information\n",
    "\n",
    "***\n",
    "\n",
    "**Detailed Description Below:**\n",
    "***\n",
    "- Above is an illustration of a Convolutional Neural Network (CNN) architecture for sentence classification\n",
    "- Here we depict three filter region sizes: 2, 3 and 4, each of which each has 2 filters\n",
    "    - Every filter performs convolution on the sentence matrix and generates (variable-length) feature maps\n",
    "- Then 1-max pooling is performed over each map\n",
    "    - i.e. The largest number from each feature map is recorded\n",
    "- Thus a univariate feature vector is generated from all six maps\n",
    "- These 6 features are then concatenated to form a feature vector for the penultimate layer\n",
    "- The final softmax layer then receives this feature vector as input and uses it to classify the sentence\n",
    "    - We assume binary classification and hence depict two possible output states\n",
    "    \n",
    "**Source:** ***Zhang, Y., & Wallace, B. (2015). A Sensitivity Analysis of (and Practitioners’ Guide to) Convolutional Neural Networks for Sentence Classification.***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "![CNN_FOR_NLP](inline_images/2range.gif)\n",
    "\n",
    "            Fig. 11. GIF showing how the convolution operation (With a Range of 2) Would Move Over the Sentance\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "![CNN_FOR_NLP](inline_images/3range.gif)\n",
    "\n",
    "            Fig. 12. GIF showing how the convolution operation (With a Range of 3) Would Move Over the Sentance\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "![CNN_FOR_NLP](inline_images/4range.gif)\n",
    "\n",
    "            Fig. 13. GIF showing how the convolution operation (With a Range of 4) Would Move Over the Sentance\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## <font color=red>Uh-Oh </font> : Are <font color=darkcyan>Convolutional Neural Networks</font> a Bad Fit for <font color=darkpink>Natural Language Processing</font> ??\n",
    "***\n",
    "\n",
    "We discussed earlier than CNN's made intuitive sense for image processing tasks as they are built to handle the two main requirements of the task, location invariance and local compositionality.\n",
    "- While location invariance might seem to make sense at first (where a word appears in a sentance could seem important...), we soon start to realize that it may not be as important as other things.\n",
    "    - Words that are close together in a sentance are often related but not always\n",
    "    - Sometimes words from much earlier in a sentnace or from a previous sentance may have a large impact\n",
    "- Local compositionality, similarily, may seem like an adequate tool for use in NLP as certain words may build higher conceptual ideas by compounding other words (adjectives modifying nouns, adverbs, and other modifiers, etc.)\n",
    "    - However, how this is actually used to make sense of language is far from obvious\n",
    "- Unlike with image processing, NLP does not seem to be an intuitive fit for CNNs\n",
    "\n",
    "***\n",
    "              SIDENOTE: RNNs (Recurrent Neurel Networks) are a MUCH more intuitive fit for modelling NLP tasks\n",
    "                        as they are sequential models that are more similar in structure and function to how humans\n",
    "                        think and speak\n",
    "***\n",
    "All this being said, a model does not have to be perfect, or even that good, to be useful. \n",
    "- A common approach in modern times has simply been counting the number of occurences of words in a sentance/paragraph and drawing conclusions\n",
    "    - This is inherently flawed, yet it still has great utility in many cases\n",
    "\n",
    "The main benefit that makes CNNs a worthwhile departure for certain NLP tasks are the **speed and efficency gains that they will yield when compared with more intuitive operations and models (RNNs)**\n",
    "- This may seem like a small benefit, but when you consider an [N-Gram](https://en.wikipedia.org/wiki/N-gram) model ([K-Mer](https://en.wikipedia.org/wiki/K-mer) in genomics), which is what Google currently uses to predict what words you may wish to search, it becomes obvious that it's a big deal\n",
    "    - Google is limited to N-Grams no larger than 5 due to computational limits\n",
    "    - CNNs can calculate much larger N-Grams with relatively little computational stress\n",
    "    - If Google struggles computationally with something it is pretty obvious that the task is computationally very intensive\n",
    "    \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## <font color=purple>Hyperparameter Exploration </font> for <font color=darkcyan>Convolutional Neural Networks</font>\n",
    "***\n",
    "\n",
    "Before we dive into the model, it makes sense to explore some of the hyperparameters that we will be navigating through, what they are, how we can change them to best suit our model, and how they relate differently to NLP than Image Processing.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## <font color=purple>Hyperparameter Exploration (1)</font> --- Narrow V. Wide Convolutions\n",
    "***\n",
    "\n",
    "A **narrow convolution**, also known as a non-padded convolution, is the simplest type of convolution.\n",
    "- It involves applying a kernel over all of the images pixels without adding or taking anything away from the original image\n",
    "- The output is a matrix that is smaller by a predictable amount\n",
    "![Narrow Convolution](inline_images/no_padding_conv.gif)\n",
    "\n",
    "                    Fig. 14. GIF showing how a narrow convolution operation works on a 5x5 image\n",
    "\n",
    "***\n",
    "A **wide convolution**, also known as a padded (or zero-padded) convolution, is a convolution that involves padding the edges of the original image with zeros\n",
    "- This is so that the kernel can access all pixels (from the original image) with the center of the kernel\n",
    "- This has the added benefit that the output shape of the new matrix is the same shape as the original image\n",
    "![Wide Convolution](inline_images/zero_padded_conv.gif)\n",
    "\n",
    "                    Fig. 15. GIF showing how a wide convolution operation works on a 5x5 image\n",
    "\n",
    "\n",
    "***\n",
    "**The equations to calculate the output matrices width and height are as follows :**\n",
    "\n",
    "***\n",
    "     \n",
    "     Let P = Padding\n",
    "     Let OMW = Output Matrix Width        Let W = Width        Let Fw = Filter Width        Let Sw = Stride Width\n",
    "     Let OMH = Output Matrix Height       Let H = Height       Let Fh = Filter Height       Let Sh = Stride Height             \n",
    "***\n",
    "\\begin{equation}\n",
    "OMW = \\frac{W - F_w + 2P}{S_w} + 1\n",
    "\\end{equation}\n",
    "***\n",
    "\\begin{equation}\n",
    "OMH = \\frac{H - F_h + 2P}{S_h} + 1\n",
    "\\end{equation}\n",
    "\n",
    "***\n",
    "\n",
    "**Using the Padded Gif Above As An Example:**\n",
    "\n",
    "\n",
    "- **P = 1**\n",
    "- **W = 5**\n",
    "- **H = 5**\n",
    "- **Fw = 3**\n",
    "- **Fh = 3**\n",
    "- **Sw = 1**\n",
    "- **Sh = 1**\n",
    "***\n",
    "**OUTPUT MATRIX WIDTH**\n",
    "\\begin{equation}\n",
    "OMW = \\frac{W - F_w + 2P}{S_w} + 1\\\\\n",
    "OMW = \\frac{5-3+2}{1} + 1\\\\\n",
    "OMW = 5\n",
    "\\end{equation}\n",
    "***\n",
    "**OUTPUT MATRIX HEIGHT**\n",
    "\\begin{equation}\n",
    "OMH = \\frac{H - F_h + 2P}{S_h} + 1\\\\\n",
    "OMH = \\frac{5-3+2}{1} + 1\\\\\n",
    "OMH = 5\n",
    "\\end{equation}\n",
    "***\n",
    "**Therefore the output dimensions are (5,5)... the same as the input image**\n",
    "- This is a traditional example of zero-padding, which I personally refer to as *'same padding'* or a *'same convolution'*\n",
    "    - Because the outupt size is the *'same'* as the input size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## <font color=purple>Hyperparameter Exploration (2)</font> --- Stride Size\n",
    "***\n",
    "\n",
    "Another hyperparameter for your convolutions is the **stride size**\n",
    "- This is defining by how much you want to shift your filter at each step\n",
    "- In all the examples above the stride size was 1\n",
    "    - As such, consecutive applications of the filter would overlap\n",
    "- A larger stride size leads to fewer applications of the filter and a smaller output size\n",
    "\n",
    "***\n",
    "**The following from the Stanford CS231 class [website](http://cs231n.github.io/convolutional-networks/)\n",
    " shows stride sizes of 1 and 2 applied to a one-dimensional input:**\n",
    "![Stride Sizing](inline_images/stride.png)\n",
    "\n",
    "    Fig. 16.         Convolution Stride Size 1                                   Convolution Stride Size 2\n",
    "***\n",
    "\n",
    "**Typically, in image processing, convolutional neural networks use a stride size of 1 so as not to miss any information (unless downsampling is desired)**\n",
    "- However, for NLP, by using a larger stride we can develop a network that acts more similarily to an RNN and takes the shape of a tree\n",
    "- We can observe from the image above, that by increasing the stride of our convolution, we decrease the size and lower the density of the output matrix (increasing sparsity)\n",
    "    - This may prove useful in NLP applications and we will dive deeper later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## <font color=purple>Hyperparameter Exploration (3)</font> --- Pooling Layers\n",
    "***\n",
    "\n",
    "A key aspect of Convolutional Neural Networks are **pooling layers**\n",
    "- Pooling layers are typically applied after the convolutional layers\n",
    "- Pooling layers subsample their input (reduce the size by taking a representative sample)\n",
    "    - Note what the subsample is representating changes depending on the type of pooling\n",
    "- The most common way to do pooling it to apply a max operation to a region (or the entire convolution output)\n",
    "    - This is called max pooling\n",
    "- Another common operation is conducted by averaging the values in a region (or the entire convolution output)\n",
    "    - This is called average pooling\n",
    "***\n",
    "          NOTE: Traditionally, in image processing we pool by passing a window (say 2x2) over the entire \n",
    "                convolutional output, however, in NLP we typically apply pooling over the complete output,\n",
    "                yielding just a single number for each convolutional filter (as depicted in Fig 10)\n",
    "***\n",
    "**The following is a gif showing how traditional max pooling is conducted:**<br>\n",
    "![Stride Sizing](inline_images/maxpool_animation.gif)\n",
    "\n",
    "                      Fig. 17.    Max Pooling With a 2x2 Kernel Over a 4x4 Matrix Producing a 2x2 Matrix\n",
    "***\n",
    "\n",
    "**You might be curious as to why NLP follows a different procedure by processing the entire convolutional output into 1 number..**\n",
    "- The best answer is probably that, regardless of the shape of the convolutional output, only one number is generated\n",
    "    - This means that different sized sentances or words or paragraphs can be compared as this step will normalize them to a similar look output\n",
    "- Inherently we are, again, losing information about context by pooling\n",
    "    - If a filter is looking for the word \"great\" in a sentance, pooling may still communicate that the word \"great was found... however, it may lose the piece of information that indicates **where** in the sentance the word \"great\" occurs\n",
    "        - *This is acceptable for the reasons outlined in the 'Uh-Oh' section*\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## <font color=purple>Hyperparameter Exploration (4)</font> --- Channels\n",
    "***\n",
    "\n",
    "The last concept we need to understand are **channels**\n",
    "- Channels are different “views” of your input data\n",
    "    - In image recognition you typically have RGB (red, green, blue) channels\n",
    "        - Image channels may also be in other formats, larger, or smaller (Grayscale, LAB, HSV, RGBA, etc.) \n",
    "- You can apply convolutions across channels, either with different or equal weights\n",
    "***\n",
    "**In NLP you could imagine having various channels as well:**\n",
    "- You could have a separate channels for different word embeddings (word2vec and GloVe for example)\n",
    "- You could have a channel for the same sentence represented in different languages, or phrased in different ways\n",
    "***\n",
    "***It boils down to a different representation of the same ground truth... an image of a cat is an image of a cat and whether we view it in RGBA, Grayscale, or HSV, it does not change the fact that their is a cat present in the image***\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## What <font color=darkpink>Natural Language Processing</font> Task Are <font color=darkcyan>Convolutional Neural Networks</font> Suited For ??\n",
    "***\n",
    "**To figure out what application we want to work through we will need to look at some of the applications of CNNs to Natural Language Processing that currently exist**\n",
    "***\n",
    "**1.  Text Classification**\n",
    "- i.e. Sentiment Analysis, Spam Detection or Topic Categorization\n",
    "    - A simple architecture would be as follows\n",
    "        - Input layer is a sentence comprised of concatenated word2vec word embeddings\n",
    "        - Followed by a convolutional layer with multiple filters\n",
    "        - Followed by a max-pooling layer\n",
    "        - Followed finally by a softmax classifier\n",
    "        \n",
    "![Text Classification Network Architecture](inline_images/network_arc.png)\n",
    "\n",
    "        Fig. 18.    Network Architecture for Text Classification From Kim, Y. (2014). CNNs for Sentence Classification\n",
    "***\n",
    "**2.  Relation Extraction and Classification**\n",
    "- Identifying \"important\" facts, ideas, topics, etc. in a corpus of text\n",
    "    - This can be useful for identifying similar news articles\n",
    "    - This could be useful for pulling out facts from a body of text\n",
    "    - Other relational applications are possible as well\n",
    "***\n",
    "**3.  Semantic Information Within Sentances [-Microsoft-]**\n",
    "- How to learn semantically meaningful representations of sentences that can be used for Information Retrieval\n",
    "    - The example given in Microsft's papers includes recommending potentially interesting documents to users based on what they are currently reading\n",
    "    - The sentence representations are trained based on search engine log data\n",
    "***\n",
    "**4.  Prediction**\n",
    "- How to predict words or text based on words or text\n",
    "    - The example given is predicting hashtags based on a tweet/facebook post\n",
    "***\n",
    "\n",
    "**Having looked through the various papers, I feel as though exploring <font color=green>basic text classification</font> will be of the most interest due to the state-of-the-art performance that has recently been achieved using CNNs**\n",
    "- Note that we will implement a model similar to Kim Yoon’s Convolutional Neural Networks for Sentence Classification. The model presented in the paper achieves good classification performance across a range of text classification tasks (like Sentiment Analysis) and has since become a standard baseline for new text classification architectures\n",
    "    - This is model and architecture discussed above and illustrated in *Fig. 18.*\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## DOWN TO BUSINESS ! \n",
    "## CODE AND TASK DESCRIPTION START HERE !\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# <center><br>Implementing a CNN for Text Classification\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## <center><br>Data and Preprocessing\n",
    "***\n",
    "The dataset we’ll use is the Movie Review data from Rotten Tomatoes – one of the data sets also used in the original paper\n",
    "- The dataset contains 10,662 example review sentences, half positive and half negative\n",
    "- The dataset has a vocabulary size of around 20,000 words\n",
    "\n",
    "        - NOTE: Since this represents a relatively small amount of data we’re likely to overfit with a powerful model. \n",
    "***                \n",
    "**<center>The following are the preprocessing steps we will need to take before we can start implementing the CNN**\n",
    "***\n",
    "**Step 1  :**\n",
    "- Load positive and negative sentences from the raw data files\n",
    "***\n",
    "**Step 2  :**\n",
    "- Clean the text data using the same code as the original paper\n",
    "***\n",
    "**Step 3  :**\n",
    "- Pad each sentence to the maximum sentence length, which turns out to be 59\n",
    "    - To do this we append special <PAD> tokens to all the sentences that are not 59 words long to make them 59 words long\n",
    "        - This allows us to efficiently batch our data since each example in a batch must be of the same length\n",
    "\n",
    "***\n",
    "**Step 4  :**\n",
    "- Build a vocabulary index and map each word to an integer between 0 and 18,765 (the vocabulary size)\n",
    "    - Therefore each sentence becomes a vector of integers (embedding)\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### <center><br>Step 0 : Importing the Necessary Libraries\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### <center><br>Step 1 & 2 : Define Functions to Load and Clean Positive and Negative Sentances From Raw Data Files\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_str(string):\n",
    "\n",
    "    \"\"\"\n",
    "    DESCRIPTION :   Tokenization/string cleaning for all datasets except for SST.\n",
    "    ARGUMENTS   :   A String (Sentance Usually)\n",
    "    RETURNS     :   Tokenized string\n",
    "    \"\"\"\n",
    "    \n",
    "    # re.sub() -- https://docs.python.org/3/library/re.html\n",
    "    # re.sub() -- [] is used to indicate sets or individual requirements to remove\n",
    "    # re.sub() -- starting with ^ tells the expression to look for the complement (things not listed within)\n",
    "    # re.sub() -- r\"\" starting with an r allows for backslashes and other special characters to be treated normally\n",
    "    \n",
    "    # This re.sub will remove all characters not found within the square brakets by replacing them with a space\n",
    "    string = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", string)\n",
    "\n",
    "    # These re.subs will space any contractions so they are seperate from the root word \n",
    "    string = re.sub(r\"\\'s\", \" \\'s\", string)\n",
    "    string = re.sub(r\"\\'ve\", \" \\'ve\", string)\n",
    "    string = re.sub(r\"n\\'t\", \" n\\'t\", string)\n",
    "    string = re.sub(r\"\\'re\", \" \\'re\", string)    \n",
    "    string = re.sub(r\"\\'d\", \" \\'d\", string)\n",
    "    string = re.sub(r\"\\'ll\", \" \\'ll\", string)\n",
    "    \n",
    "    # This re.sub will space punctuation so that it is not connected to the trailing word\n",
    "    string = re.sub(r\",\", \" , \", string)\n",
    "    string = re.sub(r\"!\", \" ! \", string)\n",
    "    string = re.sub(r\"\\(\", \" \\( \", string)\n",
    "    string = re.sub(r\"\\)\", \" \\) \", string)    \n",
    "    string = re.sub(r\"\\?\", \" \\? \", string)\n",
    "    \n",
    "    # This re.sub will do something... I'm not sure   \n",
    "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
    "    \n",
    "    # .strip() method removes leading and trailing spaces when not used with any argument\n",
    "    string = string.strip()\n",
    "    \n",
    "    # .lwer() method changes all letters to lowercase\n",
    "    string = string.lower()\n",
    "    \n",
    "    return string\n",
    "\n",
    "\n",
    "def load_data_and_labels(positive_data_file, negative_data_file):\n",
    "    \n",
    "    \"\"\"\n",
    "    DESCRIPTION :   Loads MR polarity data from files, splits the data into words and generates labels.\n",
    "    ARGUMENTS   :   Raw negative and positive data files\n",
    "    RETURNS     :   Split sentences and labels\n",
    "    \"\"\"\n",
    "    \n",
    "    # ----------------------------------------------------------------------------    \n",
    "    #                      Load Positive Data From Files\n",
    "    # ----------------------------------------------------------------------------\n",
    "    \n",
    "    # open() - Returns a file object, and is most commonly used with two arguments: open(filename, mode)\n",
    "    #          -- The first argument is a string containing the filename [filename]\n",
    "    #          -- The second argument is a string containing characters that describe how the file will be used [mode]\n",
    "    #             --- Mode can be 'r'  when the file will only be read (This is the default argument)\n",
    "    #             --- Mode can be 'w'  when the file be written to (existing file with the same name will be erased)\n",
    "    #             --- Mode can be 'a'  when the file will be appended (indexed to the end where text will be added)\n",
    "    #             --- Mode can be 'r+' when the file will be read and written to\n",
    "    #\n",
    "    positive_examples_file = open(positive_data_file, \"r\", encoding='utf-8')\n",
    "    \n",
    "    # .readlines() - The method readlines() reads until EOF using readline() and returns a list containing the lines\n",
    "    #                -- Note that each item in the list is the next sequential line in the file\n",
    "    #\n",
    "    positive_examples_line_by_line = positive_examples_file.readlines()\n",
    "\n",
    "    # .strip() - A method to remove parts of a string\n",
    "    #            -- if no argument is passed than the method will remove whitespace (leading and trailing)\n",
    "    #            -- Note than an argument can be passed and if found in the sentance/word than it will be removed\n",
    "    #               --- i.e. if the sentance is \"I see cats\" and you command sentance.strip(\"s\") than it outputs \"I ee cat\"\n",
    "    #               --- for our case if the sentance is \"  I see cats \" and you command sentance.strip() than it outputs \"I see cats\"\n",
    "    #\n",
    "    positive_examples = [s.strip() for s in positive_examples_line_by_line]\n",
    " \n",
    "    # ----------------------------------------------------------------------------\n",
    "    \n",
    "    \n",
    "    # ----------------------------------------------------------------------------\n",
    "    #                      Load Negative Data From Files\n",
    "    # ----------------------------------------------------------------------------\n",
    "    \n",
    "    # Follows the exact same procedure as detailed in more depth above (for positive data)\n",
    "    negative_examples_file = open(negative_data_file, \"r\", encoding='utf-8')\n",
    "    negative_examples_line_by_line = negative_examples_file.readlines()\n",
    "    negative_examples = [s.strip() for s in negative_examples_line_by_line]\n",
    "    \n",
    "    # ----------------------------------------------------------------------------\n",
    "\n",
    "    \n",
    "    # ----------------------------------------------------------------------------\n",
    "    #                              Split by Words\n",
    "    # ----------------------------------------------------------------------------\n",
    "\n",
    "    # Combine the corpuses into one large corpus containing all of the positive and negative examples\n",
    "    x_text = positive_examples + negative_examples\n",
    "    \n",
    "    # Clean all of the strings using the function clean_str which will be described later\n",
    "    x_text = [clean_str(sentance) for sentance in x_text]\n",
    "\n",
    "    # ----------------------------------------------------------------------------\n",
    "\n",
    "    \n",
    "    # ----------------------------------------------------------------------------\n",
    "    #                              Generate labels\n",
    "    # ----------------------------------------------------------------------------\n",
    "\n",
    "    # One-hot-encode all of the examples to either be positive or negative\n",
    "    #   -- positive = [0, 1]\n",
    "    #   -- negative = [1, 0])\n",
    "    positive_labels = [[0, 1] for _ in positive_examples]\n",
    "    negative_labels = [[1, 0] for _ in negative_examples]\n",
    "    \n",
    "    # ----------------------------------------------------------------------------\n",
    "\n",
    "    \n",
    "    # ----------------------------------------------------------------------------\n",
    "    #                     Concatenate all Labels Together\n",
    "    # ----------------------------------------------------------------------------\n",
    "\n",
    "    y = np.concatenate([positive_labels, negative_labels], 0)\n",
    "    \n",
    "    # ----------------------------------------------------------------------------\n",
    "\n",
    "    # ----------------------------------------------------------------------------    \n",
    "    # Return sentances (that have been split) and label\n",
    "    # ----------------------------------------------------------------------------\n",
    "\n",
    "    return [x_text, y]\n",
    "\n",
    "    # ----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### <center><br>Step 3 : Pad Each Sentence to the Maximum Sentence Length\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['plot two teen couples go to a church party , drink and then drive', 'they get into an accident', 'one of the guys dies , but his girlfriend continues to see him in her life , and has nightmares', \"what 's the deal \\\\?\", 'watch the movie and sorta find out', 'critique a mind fuck movie for the teen generation that touches on a very cool idea , but presents it in a very bad package', \"which is what makes this review an even harder one to write , since i generally applaud films which attempt to break the mold , mess with your head and such \\\\( lost highway memento \\\\) , but there are good and bad ways of making all types of films , and these folks just did n't snag this one correctly\", 'they seem to have taken this pretty neat concept , but executed it terribly', 'so what are the problems with the movie \\\\?', \"well , its main problem is that it 's simply too jumbled\", \"it starts off normal but then downshifts into this fantasy world in which you , as an audience member , have no idea what 's going on\", 'there are dreams , there are characters coming back from the dead , there are others who look like the dead , there are strange apparitions , there are disappearances , there are a looooot of chase scenes , there are tons of weird things that happen , and most of it is simply not explained', \"now i personally do n't mind trying to unravel a film every now and then , but when all it does is give me the same clue over and over again , i get kind of fed up after a while , which is this film 's biggest problem\", \"it 's obviously got this big secret to hide , but it seems to want to hide it completely until its final five minutes\", 'and do they make things entertaining , thrilling or even engaging , in the meantime \\\\?', 'not really', \"the sad part is that the arrow and i both dig on flicks like this , so we actually figured most of it out by the half way point , so all of the strangeness after that did start to make a little bit of sense , but it still did n't the make the film all that more entertaining\", 'i guess the bottom line with movies like this is that you should always make sure that the audience is into it even before they are given the secret password to enter your world of understanding', 'i mean , showing melissa sagemiller running away from visions for about 20 minutes throughout the movie is just plain lazy ! !', 'okay , we get it there', \"are people chasing her and we do n't know who they are\", 'do we really need to see it over and over again \\\\?', 'how about giving us different scenes offering further insight into all of the strangeness going down in the movie \\\\?', 'apparently , the studio took this film away from its director and chopped it up themselves , and it shows', \"there might 've been a pretty decent teen mind fuck movie in here somewhere , but i guess the suits decided that turning it into a music video with little edge , would make more sense\", 'the actors are pretty good for the most part , although wes bentley just seemed to be playing the exact same character that he did in american beauty , only in a new neighborhood', \"but my biggest kudos go out to sagemiller , who holds her own throughout the entire film , and actually has you feeling her character 's unraveling\", \"overall , the film does n't stick because it does n't entertain , it 's confusing , it rarely excites and it feels pretty redundant for most of its runtime , despite a pretty cool ending and explanation to all of the craziness that came before it\", \"oh , and by the way , this is not a horror or teen slasher flick it 's\", 'just packaged to look that way because someone is apparently assuming that the genre is still hot with the kids', 'it also wrapped production two years ago and has been sitting on the shelves ever since', 'whatever skip', 'it !', \"where 's joblo coming from \\\\?\", 'a nightmare of elm street 3 \\\\( 7 10 \\\\) blair witch 2 \\\\( 7 10 \\\\) the crow \\\\( 9 10 \\\\) the crow salvation \\\\( 4 10 \\\\) lost highway \\\\( 10 10 \\\\) memento \\\\( 10 10 \\\\) the others \\\\( 9 10 \\\\) stir of echoes \\\\( 8 10 \\\\)', \"films adapted from comic books have had plenty of success , whether they 're about superheroes \\\\( batman , superman , spawn \\\\) , or geared toward kids \\\\( casper \\\\) or the arthouse crowd \\\\( ghost world \\\\) , but there 's never really been a comic book like from hell before\", \"for starters , it was created by alan moore \\\\( and eddie campbell \\\\) , who brought the medium to a whole new level in the mid '80s with a 12 part series called the watchmen\", 'to say moore and campbell thoroughly researched the subject of jack the ripper would be like saying michael jackson is starting to look a little odd', 'the book \\\\( or graphic novel , if you will \\\\) is over 500 pages long and includes nearly 30 more that consist of nothing but footnotes', \"in other words , do n't dismiss this film because of its source\", \"if you can get past the whole comic book thing , you might find another stumbling block in from hell 's directors , albert and allen hughes\", \"getting the hughes brothers to direct this seems almost as ludicrous as casting carrot top in , well , anything , but riddle me this who better to direct a film that 's set in the ghetto and features really violent street crime than the mad geniuses behind menace ii society \\\\?\", \"the ghetto in question is , of course , whitechapel in 1888 london 's east end\", \"it 's a filthy , sooty place where the whores \\\\( called unfortunates \\\\) are starting to get a little nervous about this mysterious psychopath who has been carving through their profession with surgical precision\", 'when the first stiff turns up , copper peter godley \\\\( robbie coltrane , the world is not enough \\\\) calls in inspector frederick abberline \\\\( johnny depp , blow \\\\) to crack the case', 'abberline , a widower , has prophetic dreams he unsuccessfully tries to quell with copious amounts of absinthe and opium', \"upon arriving in whitechapel , he befriends an unfortunate named mary kelly \\\\( heather graham , say it is n't so \\\\) and proceeds to investigate the horribly gruesome crimes that even the police surgeon ca n't stomach\", \"i do n't think anyone needs to be briefed on jack the ripper , so i wo n't go into the particulars here , other than to say moore and campbell have a unique and interesting theory about both the identity of the killer and the reasons he chooses to slay\", \"in the comic , they do n't bother cloaking the identity of the ripper , but screenwriters terry hayes \\\\( vertical limit \\\\) and rafael yglesias \\\\( les mis \\\\? rables \\\\) do a good job of keeping him hidden from viewers until the very end\", \"it 's funny to watch the locals blindly point the finger of blame at jews and indians because , after all , an englishman could never be capable of committing such ghastly acts\", \"and from hell 's ending had me whistling the stonecutters song from the simpsons for days \\\\( who holds back the electric car who made steve guttenberg a star \\\\? \\\\)\", \"do n't worry it 'll all make sense when you see it\", \"now onto from hell 's appearance it 's certainly dark and bleak enough , and it 's surprising to see how much more it looks like a tim burton film than planet of the apes did \\\\( at times , it seems like sleepy hollow 2 \\\\)\", \"the print i saw was n't completely finished \\\\( both color and music had not been finalized , so no comments about marilyn manson \\\\) , but cinematographer peter deming \\\\( do n't say a word \\\\) ably captures the dreariness of victorian era london and helped make the flashy killing scenes remind me of the crazy flashbacks in twin peaks , even though the violence in the film pales in comparison to that in the black and white comic\", \"oscar winner martin childs' \\\\( shakespeare in love \\\\) production design turns the original prague surroundings into one creepy place\", 'even the acting in from hell is solid , with the dreamy depp turning in a typically strong performance and deftly handling a british accent', \"ians holm \\\\( joe gould 's secret \\\\) and richardson \\\\( 102 dalmatians \\\\) log in great supporting roles , but the big surprise here is graham\", \"i cringed the first time she opened her mouth , imagining her attempt at an irish accent , but it actually was n't half bad\", 'the film , however , is all good', '2 00 r for strong violence gore , sexuality , language and drug content']\n"
     ]
    }
   ],
   "source": [
    "_ = load_data_and_labels(\"./data/neg/cv000_29416.txt\", \"./data/pos/cv000_29590.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
